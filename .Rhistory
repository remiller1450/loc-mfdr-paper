rbind(tab2_v2, c(last_row, tab2_lr[3:4,3]))
# final %>% group_by(condition, timingpost) %>% summarize( tasks = n(), n_dept = sum(dept_3s), perc = sum(dept_3s)/n())
# final %>% group_by(condition, timingpost, dept) %>% summarize(dur = mean(minor_ool)/60)
### Model #1 - any lane departure -- Note: not viable to model major depts due to lack of occurrences
m1 = glmer(dept ~ (1|subject) + timingpost + condition + timingpost:condition + scenario + init_lp, data = final,
family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
m1b = glmer(dept ~ (1|subject) + timingpost + condition + timingpost:condition + scenario + ns(seq)*condition, data = final,
family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
AIC(m1)
AIC(m1b) ## Including sequence (learning) effect is not worthwhile
emmeans_results1 <- emmeans(m1, ~ timingpost*condition)
## W/in group contrasts and OR
m1_wic = contrast(emmeans_results1, "revpairwise", by="condition")
m1_wic_OR = exp(summary(m1_wic)$estimate)
m1_wic_LCL = exp(summary(m1_wic)$estimate - 1.96*summary(m1_wic)$SE)
m1_wic_UCL = exp(summary(m1_wic)$estimate + 1.96*summary(m1_wic)$SE)
m1_wic_pv = summary(m1_wic)$p.value
data.frame(OR = m1_wic_OR, LCL = m1_wic_LCL, UCL = m1_wic_UCL, p_value = m1_wic_pv)
## B/w group p-values
summary(m1)
# Re-fit changing ref to get occ vs. daily
m = glmer(dept ~ (1|subject) + timingpost + condition_Occ_Ref + timingpost:condition_Occ_Ref + scenario + init_lp, data = final,
family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(m)
### Model #2 - SDLP --- Note: random effect estimated to have zero variance, therefore removed as unnecessary
final$sdlp5_cm = final$sdlp5*30.48
m2 = lm(sdlp5_cm ~ timingpost + condition + timingpost:condition + scenario  + init_spd, data = final)
m2b = lm(sdlp5_cm ~ timingpost + condition + timingpost:condition + scenario + ns(seq)*condition + init_spd, data = final)
AIC(m2)
AIC(m2b) ## Including sequence (learning) effect is not worthwhile
emmeans_results2 <- emmeans(m2, ~ timingpost*condition)
## W/in group contrasts and CI
m2_wic = contrast(emmeans_results2, "revpairwise", by="condition")
m2_wic_eff = summary(m2_wic)$estimate
m2_wic_LCL = summary(m2_wic)$estimate - 1.96*summary(m2_wic)$SE
m2_wic_UCL = summary(m2_wic)$estimate + 1.96*summary(m2_wic)$SE
m2_wic_pv = summary(m2_wic)$p.value
data.frame(Eff = m2_wic_eff, LCL = m2_wic_LCL, UCL = m2_wic_UCL, p_value = m2_wic_pv)
## b/w group p-vals
summary(m2)
## Change ref for occ v. daily comp
m = lm(sdlp5_cm ~ timingpost + condition_Occ_Ref + timingpost:condition_Occ_Ref + scenario + init_spd, data = final)
summary(m)
## Model #3 - Initial speed
final$init_spd_km = final$ch_spd*1.609 - final$init_spd*1.609
m3 = lm(init_spd_km ~ timingpost + condition + timingpost:condition + scenario , data = final)
m3b = lm(init_spd_km ~ timingpost + condition + timingpost:condition + scenario + ns(seq)*condition, data = final)
AIC(m3)
AIC(m3b)  ## Seq/learning effect doesn't matter
emmeans_results3 <- emmeans(m3, ~ timingpost*condition)
# Re-fit changing ref to get occ vs. daily
m = glmer(dept ~ (1|subject) + timingpost + condition_Occ_Ref + timingpost:condition_Occ_Ref + scenario + init_lp, data = final,
family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
summary(m)
exp(0.86612)
## B/w group p-values
summary(m1)
exp(1.87786)
exp(1.01174)
### Model #2 - SDLP --- Note: random effect estimated to have zero variance, therefore removed as unnecessary
final$sdlp5_cm = final$sdlp5*30.48
m2 = lm(sdlp5_cm ~ timingpost + condition + timingpost:condition + scenario  + init_spd, data = final)
m2b = lm(sdlp5_cm ~ timingpost + condition + timingpost:condition + scenario + ns(seq)*condition + init_spd, data = final)
AIC(m2)
AIC(m2b) ## Including sequence (learning) effect is not worthwhile
emmeans_results2 <- emmeans(m2, ~ timingpost*condition)
## W/in group contrasts and CI
m2_wic = contrast(emmeans_results2, "revpairwise", by="condition")
m2_wic_eff = summary(m2_wic)$estimate
m2_wic_LCL = summary(m2_wic)$estimate - 1.96*summary(m2_wic)$SE
m2_wic_UCL = summary(m2_wic)$estimate + 1.96*summary(m2_wic)$SE
m2_wic_pv = summary(m2_wic)$p.value
data.frame(Eff = m2_wic_eff, LCL = m2_wic_LCL, UCL = m2_wic_UCL, p_value = m2_wic_pv)
## b/w group p-vals
summary(m2)
## Change ref for occ v. daily comp
m = lm(sdlp5_cm ~ timingpost + condition_Occ_Ref + timingpost:condition_Occ_Ref + scenario + init_spd, data = final)
summary(m)
## Model #4 - Centering behavior
m4 = glmer(center ~ (1|subject) + timingpost + condition + timingpost:condition + scenario, data = final,
family = "binomial")
m4b = glmer(center ~ (1|subject) + timingpost + condition + timingpost:condition + scenario + ns(seq)*condition, data = final,
family = "binomial")
AIC(m4)
AIC(m4b)
emmeans_results4 <- emmeans(m4, ~ timingpost*condition)  ## No learning effect needed
## W/in group contrasts and OR
m4_wic = contrast(emmeans_results4, "revpairwise", by="condition")
m4_wic_OR = exp(summary(m4_wic)$estimate)
m4_wic_LCL = exp(summary(m4_wic)$estimate - 1.96*summary(m4_wic)$SE)
m4_wic_UCL = exp(summary(m4_wic)$estimate + 1.96*summary(m4_wic)$SE)
m4_wic_pv = summary(m4_wic)$p.value
data.frame(OR = m4_wic_OR, LCL = m4_wic_LCL, UCL = m4_wic_UCL, p_value = m4_wic_pv)
## B/w grp p-val
summary(m4)
c(exp(-0.27619), exp(0.22661))
## Change ref for occ v. daily comp
m = glmer(center ~ (1|subject) + timingpost + condition_Occ_Ref + timingpost:condition_Occ_Ref + scenario, data = final,
family = "binomial")
summary(m)
exp(0.5029)
1/250
1/10000
1 - (1/250 + 1/10000 + 1/3000)
10000/250 + 40000/3000 + 200000/10000
(1 - (1/250 + 1/10000 + 1/3000))*(0 - 73.333)^2 + 1/250*(10000 - 73.333)^2 + 1/3000*(40000 - 73.3333)^2 + 1/10000*(200000 - 73.333)^2
sqrt(4927956)
m146s01 = c("Connor Anderson", "Frankie Biffath","Lauren Briggs","David Brophy","Kayleigh Bush","Tom Cobb","Cameron Cyran","Anthony Dafforn","Laura DeNeve","Amanda Duminuco","Avery Dzurko","Sarah Fitch","Charles Johnson","Cristabel Kleiner","Erin Linko","Max Mesa","Claire Pape","Nevaeh Perkins","Bolu Salami","Benjamin Seibert","Sara Street","Abby Stumpf","Molly Sturm","Ana Torres","Renee White","Karolina Zawadzka")
get_groups <- function(roster, size = 4){
n = ceiling(length(roster)/size)
v = rep(1:n, length.out = length(roster))
out = data.frame(Name = roster, Group = sample(v, replace = FALSE))
return(out)
}
## Get groups
g <- get_groups(m146s01, size = 5)  ## 8am
## View groups
View(g)
## Randomly call on group
sample(1:max(g$Group), size = 1)
m146s02 = c("Miranda Basta","Brea Bauer","Olivia Bigham","Jason Bliss","Morgan Bowen","Richelle Cameron", "Aaliyah Coleman","Laura Cox","Fatoumata Diallo","Annabelle Fisher","Dylan Fraley","Amanda Hagedorn","Megan Humphry","Zach Kane","Cristabel Kleiner","Maeve Kruser","Ciara Lambert","Ant Mastrogiovanni-Washington","Samantha McCann","Sophia McDermott","Baylor McKinney","Isabella Roscoe","Max Rothkopf","Devon Terry","Anthony Toweson","Lizzie Troup")
get_groups <- function(roster, size = 4){
n = ceiling(length(roster)/size)
v = rep(1:n, length.out = length(roster))
out = data.frame(Name = roster, Group = sample(v, replace = FALSE))
return(out)
}
g <- get_groups(m146s02, size = 5)  ## 9am
## View groups
View(g)
## Randomly call on group
sample(1:max(g$Group), size = 1)
readPNG
install.packages("PNG")
install.packages("png")
library(png)
readPNG
?readPNG
?rasterImage
sqrt(.7*.3/39)
####################################################################################################
#
#
#   Filename    :	case_study_sim.R
#   Input data files  :    ---
#   Output data files :    table5.pdf
#
#   Required R packages :  ggplot2, ncvreg, Matrix, survival, covTest, selectiveInference
#                          Rccp, gridExtra, locfdr, grid, reshape2, hdi, knockoff
#
#
####################################################################################################
library(ggplot2)
library(ncvreg)
library(Matrix)
library(survival)
library(covTest)
library(selectiveInference)
library(gridExtra)
library(locfdr)
library(grid)
library(reshape2)
library(hdi)
library(knockoff)
## Sets the working directory to current location of this folder
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## Sources functions used in the simulations and the construction of figures
source("functions.R")
## Load TCGA BRCA1 dataset
TCGA <- readRDS("case_study_data//bcTCGA.rds")
## Standardize X matrix
XX <- std(TCGA$X)
## Find 5 max beta's (used to make simulated beta realistic)
init.fit = cv.ncvreg(X = XX, y = TCGA$y, penalty = "lasso")
sort(abs(init.fit$fit$beta[-1,which(init.fit$lambda == init.fit$lambda.min)]), decreasing = TRUE)[1:5]
## Seed
set.seed(133)
nrep = 100
tp = tot = matrix(NA, nrow = nrep, ncol = 4)
for(i in 1:nrep){
## 20 causal features
cause_id = sample(1:ncol(XX), size = 20, replace = FALSE)
beta = rep(0, ncol(XX))
## chosen to reflect slightly larger effects than present in real data
beta[cause_id] = c(rep(0.4, 10), rep(0.2, 10))
## Outcome
y = XX %*% beta + rnorm(nrow(XX), 0, sd = 1)
## Model fit
cv.fit <- cv.ncvreg(XX, y, penalty = "lasso")
## mfdr selections
cv.mfdr.res = local_mfdr(cv.fit$fit, cv.fit$lambda.min)
sel_id = which(cv.mfdr.res$mfdr < 0.1)
### CV selections
cv_sel_id = which(cv.fit$fit$beta[-1,which(cv.fit$lambda == cv.fit$lambda.min)] != 0)
### Univariate testing
tstat <- numeric(ncol(XX))
for (j in 1:ncol(XX)){
fit.lm <- lm(y ~ XX[,j])
tstat[j] <- summary(fit.lm)$coefficients[2,3]
}
zstat <- qnorm(pt(tstat,nrow(XX) - 2))
zstat[is.infinite(zstat)] <- tstat[is.infinite(zstat)] ## Make infinite z-stats into their pre-transformed t-stat
univariate.res <- locfdr(zstat, nulltype = 0, plot = 0, df = 10)
uni_sel_id = which(univariate.res$fdr < 0.1)
### Knock-off Filter
#suppressWarnings(knres <- knockoff.filter(X = XX, y = y, fdr = .1))
### selective inf
fit.lar <- tryCatch(lar(XX,y, maxsteps = 26), error=function(e) NULL)
sig.est <- tryCatch(estimateSigma(X, y), error=function(e) NULL)
si.res <- tryCatch(larInf(fit.lar, sigma = sig.est$sigmahat, k = 25), error=function(e) NULL)
if (!is.null(si.res)){
step.pv <- forwardStop(si.res$pv)
if (step.pv == 0){
si.tp = 0
} else if (step.pv >= 1){
si.tp = sum(si.res$vars[1:step.pv] %in% cause_id)
}
} else {
si.tp = 0
step.pv = 0
}
tp[i,] = c(sum(cause_id %in% sel_id), sum(cause_id %in% cv_sel_id), sum(cause_id %in% uni_sel_id), si.tp)
tot[i,] = c(length(sel_id), length(cv_sel_id), sum(univariate.res$fdr < 0.1), step.pv)
}
tp[is.na(tp)] = 0
tot[is.na(tot)] = 0
apply(tp, 2, mean)
apply(tot, 2, mean)
0.37/0.94
warnings()
tp
tot
res = list(tp, tot)
res
save(res, file = "case_study_sim.RData")
tp
apply(tp, 2, mean)
apply(tot, 2, mean)
14.52/147.9
1 - 14.52/147.9
(89.19 - 92.69)/sqrt(12.18^2/57 + 15.98^2/67)
(0.232 - 0.211)/sqrt(0.222*(1-0.222)/198 + 0.222*(1-0.222)/180)
m146s02 = c("Miranda Basta","Brea Bauer","Olivia Bigham","Jason Bliss","Morgan Bowen","Richelle Cameron", "Aaliyah Coleman","Laura Cox","Fatoumata Diallo","Annabelle Fisher","Dylan Fraley","Amanda Hagedorn","Megan Humphry","Zach Kane","Cristabel Kleiner","Maeve Kruser","Ciara Lambert","Ant Mastrogiovanni-Washington","Samantha McCann","Sophia McDermott","Baylor McKinney","Isabella Roscoe","Max Rothkopf","Devon Terry","Anthony Toweson","Lizzie Troup")
get_groups <- function(roster, size = 4){
n = ceiling(length(roster)/size)
v = rep(1:n, length.out = length(roster))
out = data.frame(Name = roster, Group = sample(v, replace = FALSE))
return(out)
}
g <- get_groups(m146s02, size = 5)  ## 9am
## View groups
View(g)
sqrt(.25/39)
sqrt(.7*.3/39)
0.47*0.29
## Assemble processed files
## Libraries used in analysis
library(dplyr)
library(lme4)
library(lmerTest)
library(multcomp)
library(effects)
library(emmeans)
library(ggplot2)
library(splines)
library(readr)
library(stringr)
## load all reduced files
lb1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadBrake_t1.csv")
lr1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t1.csv")
lr2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t2.csv")
li1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t1.csv")
li2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t2.csv")
rhs1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t1.csv")
rhs2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t2.csv")
## set up data.frame containing variables used for modeling
final = data.frame(subject = c(lb1$Subject, lr1$Subject, lr2$Subject, li1$Subject, li2$Subject, rhs1$Subject, rhs2$Subject),
scenario = c(lb1$Scenario, lr1$Scenario, lr2$Scenario, li1$Scenario, li2$Scenario, rhs1$Scenario, rhs2$Scenario),
seq = c(lb1$Sequence, lr1$Sequence, lr2$Sequence, li1$Sequence, li2$Sequence, rhs1$Sequence, rhs2$Sequence),
timing = tolower(c(lb1$Timing, lr1$Timing, lr2$Timing, li1$Timing, li2$Timing, rhs1$Timing, rhs2$Timing)),
condition = tolower(c(lb1$Condition, lr1$Condition, lr2$Condition, li1$Condition, li2$Condition, rhs1$Condition, rhs2$Condition)),
minor_ool5 = c(lb1$minor_ool5, lr1$minor_ool5, lr2$minor_ool5, li1$minor_ool5, li2$minor_ool5, rhs1$minor_ool5, rhs2$minor_ool5),
minor_ool = c(lb1$minor_ool, lr1$minor_ool, lr2$minor_ool, li1$minor_ool, li2$minor_ool, rhs1$minor_ool, rhs2$minor_ool),
sdlp5 = c(lb1$full_sdlp5, lr1$full_sdlp5, lr2$full_sdlp5, li1$full_sdlp5, li2$full_sdlp5, rhs1$full_sdlp5, rhs2$full_sdlp5),
sdlp3 = c(lb1$full_sdlp, lr1$full_sdlp, lr2$full_sdlp, li1$full_sdlp, li2$full_sdlp, rhs1$full_sdlp, rhs2$full_sdlp),
init_lp = abs(c(lb1$init_lp, lr1$init_lp, lr2$init_lp, li1$init_lp, li2$init_lp, rhs1$init_lp, rhs2$init_lp)),
init_spd = c(lb1$init_speed, lr1$init_speed, lr2$init_speed, li1$init_speed, li2$init_speed, rhs1$init_speed, rhs2$init_speed),
min_spd = c(lb1$min_spd, lr1$min_spd, lr2$min_spd, li1$min_spd, li2$min_spd, rhs1$min_spd, rhs2$min_spd),
max_lp = c(lb1$max_lp, lr1$max_lp, lr2$max_lp, li1$max_lp, li2$max_lp, rhs1$max_lp, rhs2$max_lp),
ch_spd = c(lb1$ch_spd, lr1$ch_spd, lr2$ch_spd, li1$ch_spd, li2$ch_spd, rhs1$ch_spd, rhs2$ch_spd),
ch_brk = c(lb1$ch_brk, lr1$ch_brk, lr2$ch_brk, li1$ch_brk, li2$ch_brk, rhs1$ch_brk, rhs2$ch_brk),
ch_cen = c(lb1$ch_cen, lr1$ch_cen, lr2$ch_cen, li1$ch_cen, li2$ch_cen, rhs1$ch_cen, rhs2$ch_cen))
table(final$condition, final$timing)
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
table(final$condition, final$timing)
## Assemble processed files
## Libraries used in analysis
library(dplyr)
library(lme4)
library(lmerTest)
library(multcomp)
library(effects)
library(emmeans)
library(ggplot2)
library(splines)
library(readr)
library(stringr)
## load all reduced files
lb1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadBrake_t1.csv")
lr1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t1.csv")
lr2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t2.csv")
li1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t1.csv")
li2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t2.csv")
rhs1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t1.csv")
rhs2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t2.csv")
## set up data.frame containing variables used for modeling
final = data.frame(subject = c(lb1$Subject, lr1$Subject, lr2$Subject, li1$Subject, li2$Subject, rhs1$Subject, rhs2$Subject),
scenario = c(lb1$Scenario, lr1$Scenario, lr2$Scenario, li1$Scenario, li2$Scenario, rhs1$Scenario, rhs2$Scenario),
seq = c(lb1$Sequence, lr1$Sequence, lr2$Sequence, li1$Sequence, li2$Sequence, rhs1$Sequence, rhs2$Sequence),
timing = tolower(c(lb1$Timing, lr1$Timing, lr2$Timing, li1$Timing, li2$Timing, rhs1$Timing, rhs2$Timing)),
condition = tolower(c(lb1$Condition, lr1$Condition, lr2$Condition, li1$Condition, li2$Condition, rhs1$Condition, rhs2$Condition)),
minor_ool5 = c(lb1$minor_ool5, lr1$minor_ool5, lr2$minor_ool5, li1$minor_ool5, li2$minor_ool5, rhs1$minor_ool5, rhs2$minor_ool5),
minor_ool = c(lb1$minor_ool, lr1$minor_ool, lr2$minor_ool, li1$minor_ool, li2$minor_ool, rhs1$minor_ool, rhs2$minor_ool),
sdlp5 = c(lb1$full_sdlp5, lr1$full_sdlp5, lr2$full_sdlp5, li1$full_sdlp5, li2$full_sdlp5, rhs1$full_sdlp5, rhs2$full_sdlp5),
sdlp3 = c(lb1$full_sdlp, lr1$full_sdlp, lr2$full_sdlp, li1$full_sdlp, li2$full_sdlp, rhs1$full_sdlp, rhs2$full_sdlp),
init_lp = abs(c(lb1$init_lp, lr1$init_lp, lr2$init_lp, li1$init_lp, li2$init_lp, rhs1$init_lp, rhs2$init_lp)),
init_spd = c(lb1$init_speed, lr1$init_speed, lr2$init_speed, li1$init_speed, li2$init_speed, rhs1$init_speed, rhs2$init_speed),
min_spd = c(lb1$min_spd, lr1$min_spd, lr2$min_spd, li1$min_spd, li2$min_spd, rhs1$min_spd, rhs2$min_spd),
max_lp = c(lb1$max_lp, lr1$max_lp, lr2$max_lp, li1$max_lp, li2$max_lp, rhs1$max_lp, rhs2$max_lp),
ch_spd = c(lb1$ch_spd, lr1$ch_spd, lr2$ch_spd, li1$ch_spd, li2$ch_spd, rhs1$ch_spd, rhs2$ch_spd),
ch_brk = c(lb1$ch_brk, lr1$ch_brk, lr2$ch_brk, li1$ch_brk, li2$ch_brk, rhs1$ch_brk, rhs2$ch_brk),
ch_cen = c(lb1$ch_cen, lr1$ch_cen, lr2$ch_cen, li1$ch_cen, li2$ch_cen, rhs1$ch_cen, rhs2$ch_cen))
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
table(final$condition, final$timing)
final %>% group_by(condition) %>% summarize(nt = n()/length(unique(subject)))
final %>% group_by() %>% summarize(nt = n()/length(unique(subject)))
final %>% group_by(condition) %>% summarize(nt = n()/length(unique(subject)))
## Assemble processed files
## Libraries used in analysis
library(dplyr)
library(lme4)
library(lmerTest)
library(multcomp)
library(effects)
library(emmeans)
library(ggplot2)
library(splines)
library(readr)
library(stringr)
## load all reduced files
lb1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadBrake_t1.csv")
lr1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t1.csv")
lr2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t2.csv")
li1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t1.csv")
li2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t2.csv")
rhs1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t1.csv")
rhs2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t2.csv")
## set up data.frame containing variables used for modeling
final = data.frame(subject = c(lb1$Subject, lr1$Subject, lr2$Subject, li1$Subject, li2$Subject, rhs1$Subject, rhs2$Subject),
scenario = c(lb1$Scenario, lr1$Scenario, lr2$Scenario, li1$Scenario, li2$Scenario, rhs1$Scenario, rhs2$Scenario),
seq = c(lb1$Sequence, lr1$Sequence, lr2$Sequence, li1$Sequence, li2$Sequence, rhs1$Sequence, rhs2$Sequence),
timing = tolower(c(lb1$Timing, lr1$Timing, lr2$Timing, li1$Timing, li2$Timing, rhs1$Timing, rhs2$Timing)),
condition = tolower(c(lb1$Condition, lr1$Condition, lr2$Condition, li1$Condition, li2$Condition, rhs1$Condition, rhs2$Condition)),
minor_ool5 = c(lb1$minor_ool5, lr1$minor_ool5, lr2$minor_ool5, li1$minor_ool5, li2$minor_ool5, rhs1$minor_ool5, rhs2$minor_ool5),
minor_ool = c(lb1$minor_ool, lr1$minor_ool, lr2$minor_ool, li1$minor_ool, li2$minor_ool, rhs1$minor_ool, rhs2$minor_ool),
sdlp5 = c(lb1$full_sdlp5, lr1$full_sdlp5, lr2$full_sdlp5, li1$full_sdlp5, li2$full_sdlp5, rhs1$full_sdlp5, rhs2$full_sdlp5),
sdlp3 = c(lb1$full_sdlp, lr1$full_sdlp, lr2$full_sdlp, li1$full_sdlp, li2$full_sdlp, rhs1$full_sdlp, rhs2$full_sdlp),
init_lp = abs(c(lb1$init_lp, lr1$init_lp, lr2$init_lp, li1$init_lp, li2$init_lp, rhs1$init_lp, rhs2$init_lp)),
init_spd = c(lb1$init_speed, lr1$init_speed, lr2$init_speed, li1$init_speed, li2$init_speed, rhs1$init_speed, rhs2$init_speed),
min_spd = c(lb1$min_spd, lr1$min_spd, lr2$min_spd, li1$min_spd, li2$min_spd, rhs1$min_spd, rhs2$min_spd),
max_lp = c(lb1$max_lp, lr1$max_lp, lr2$max_lp, li1$max_lp, li2$max_lp, rhs1$max_lp, rhs2$max_lp),
ch_spd = c(lb1$ch_spd, lr1$ch_spd, lr2$ch_spd, li1$ch_spd, li2$ch_spd, rhs1$ch_spd, rhs2$ch_spd),
ch_brk = c(lb1$ch_brk, lr1$ch_brk, lr2$ch_brk, li1$ch_brk, li2$ch_brk, rhs1$ch_brk, rhs2$ch_brk),
ch_cen = c(lb1$ch_cen, lr1$ch_cen, lr2$ch_cen, li1$ch_cen, li2$ch_cen, rhs1$ch_cen, rhs2$ch_cen))
final %>% group_by(condition) %>% summarize(nt = n()/length(unique(subject)))
final %>% group_by(condition, timing) %>% summarize(nt = n()/length(unique(subject)))
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
## Assemble processed files
## Libraries used in analysis
library(dplyr)
library(lme4)
library(lmerTest)
library(multcomp)
library(effects)
library(emmeans)
library(ggplot2)
library(splines)
library(readr)
library(stringr)
## load all reduced files
lb1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadBrake_t1.csv")
lr1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t1.csv")
lr2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeadRevealed_t2.csv")
li1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t1.csv")
li2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\LeftIncursion_t2.csv")
rhs1 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t1.csv")
rhs2 = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\CSVData\\RuralHighSpeed_t2.csv")
## set up data.frame containing variables used for modeling
final = data.frame(subject = c(lb1$Subject, lr1$Subject, lr2$Subject, li1$Subject, li2$Subject, rhs1$Subject, rhs2$Subject),
scenario = c(lb1$Scenario, lr1$Scenario, lr2$Scenario, li1$Scenario, li2$Scenario, rhs1$Scenario, rhs2$Scenario),
seq = c(lb1$Sequence, lr1$Sequence, lr2$Sequence, li1$Sequence, li2$Sequence, rhs1$Sequence, rhs2$Sequence),
timing = tolower(c(lb1$Timing, lr1$Timing, lr2$Timing, li1$Timing, li2$Timing, rhs1$Timing, rhs2$Timing)),
condition = tolower(c(lb1$Condition, lr1$Condition, lr2$Condition, li1$Condition, li2$Condition, rhs1$Condition, rhs2$Condition)),
minor_ool5 = c(lb1$minor_ool5, lr1$minor_ool5, lr2$minor_ool5, li1$minor_ool5, li2$minor_ool5, rhs1$minor_ool5, rhs2$minor_ool5),
minor_ool = c(lb1$minor_ool, lr1$minor_ool, lr2$minor_ool, li1$minor_ool, li2$minor_ool, rhs1$minor_ool, rhs2$minor_ool),
sdlp5 = c(lb1$full_sdlp5, lr1$full_sdlp5, lr2$full_sdlp5, li1$full_sdlp5, li2$full_sdlp5, rhs1$full_sdlp5, rhs2$full_sdlp5),
sdlp3 = c(lb1$full_sdlp, lr1$full_sdlp, lr2$full_sdlp, li1$full_sdlp, li2$full_sdlp, rhs1$full_sdlp, rhs2$full_sdlp),
init_lp = abs(c(lb1$init_lp, lr1$init_lp, lr2$init_lp, li1$init_lp, li2$init_lp, rhs1$init_lp, rhs2$init_lp)),
init_spd = c(lb1$init_speed, lr1$init_speed, lr2$init_speed, li1$init_speed, li2$init_speed, rhs1$init_speed, rhs2$init_speed),
min_spd = c(lb1$min_spd, lr1$min_spd, lr2$min_spd, li1$min_spd, li2$min_spd, rhs1$min_spd, rhs2$min_spd),
max_lp = c(lb1$max_lp, lr1$max_lp, lr2$max_lp, li1$max_lp, li2$max_lp, rhs1$max_lp, rhs2$max_lp),
ch_spd = c(lb1$ch_spd, lr1$ch_spd, lr2$ch_spd, li1$ch_spd, li2$ch_spd, rhs1$ch_spd, rhs2$ch_spd),
ch_brk = c(lb1$ch_brk, lr1$ch_brk, lr2$ch_brk, li1$ch_brk, li2$ch_brk, rhs1$ch_brk, rhs2$ch_brk),
ch_cen = c(lb1$ch_cen, lr1$ch_cen, lr2$ch_cen, li1$ch_cen, li2$ch_cen, rhs1$ch_cen, rhs2$ch_cen))
## remove bad obs
final = final[-which(is.na(final$condition)),]  ## No dosing in disp
final = final[-which(final$min_spd < 1),]   ## Min speed nearly zero during a task window
#final = final[-which(final$subject %in% c("O_106", "O_111", "O_122", "O_127")),]  ## These four subjects only had 1 task repeat, suspcious = dropped
## remove obs according to prev exclusions
prev = read.csv("C:\\Users\\millerr33\\Documents\\CU_data\\subj_exclude.csv")
exc_id = paste0(substr(prev[prev$Exclude != "", 2], 1,1), "_", substr(prev[prev$Exclude != "", 2], 2,4))
final = final[-which(final$subject %in% exc_id),]
final %>% group_by(condition, timing) %>% summarize(nt = n()/length(unique(subject)))
Student_1N5_Cleaned <- read.csv("C:/Users/millerr33/Downloads/Student_1N5_Cleaned.csv")
View(Student_1N5_Cleaned)
is.na(Student_1N5_Cleaned)
sum(is.na(Student_1N5_Cleaned))
sum(is.na(Student_1N5_Cleaned))/length(Student_1N5_Cleaned)
sum(is.na(Student_1N5_Cleaned))/(nrow(Student_1N5_Cleaned)*ncol(Student_1N5_Cleaned))
rowSums(is.na(Student_1N5_Cleaned))
rowSums(is.na(Student_1N5_Cleaned)) > 0
sum(rowSums(is.na(Student_1N5_Cleaned)) > 0)
length(rowSums(is.na(Student_1N5_Cleaned)) > 0) ## Missing at least 1 response
sum(rowSums(is.na(Student_1N5_Cleaned)) > 0)/nrow(Student_1N5_Cleaned) ## Percentage
sum(is.na(Student_1N5_Cleaned)) ## Total missing values
sum(is.na(Student_1N5_Cleaned))/(nrow(Student_1N5_Cleaned)*ncol(Student_1N5_Cleaned)) ## Percentage (total)
sum(rowSums(is.na(Student_1N5_Cleaned)) > 0) ## Missing at least 1 response
sum(rowSums(is.na(Student_1N5_Cleaned)) > 0)/nrow(Student_1N5_Cleaned) ## Percentage (at least 1)
packageVersion("emmeans")
?emmeans
citation("emmeans")
citation("lmer")
citation("lme4")
m156s01 = c("Haley Aho","Carli Aldridge","Ella Anich","Maia Austvold","Tate Clemons","Ian Dissett","Alex Ezell","Imani Graham","Natalie Hall","Hayley Haner","Samantha Jackson","Kiya Jett","Casey Johnson","Ryan Karsten","Megan Keane", "Katie Kuc","Carter Lange","Nick Minion","Ellie Murdock","Reagan Norvell","Hannah Pugh","Nick Rothe","Ayden Scheffler","Kennedy Springfield","Cole Waymeyer","Maggie Weeks")
m156s01 = c("Haley Aho","Carli Aldridge","Ella Anich","Tate Clemons","Ian Dissett","Alex Ezell","Imani Graham","Natalie Hall","Hayley Haner","Kiya Jett","Casey Johnson","Ryan Karsten","Megan Keane", "Katie Kuc","Carter Lange","Nick Minion","Ellie Murdock","Reagan Norvell","Hannah Pugh","Nick Rothe","Ayden Scheffler","Kennedy Springfield","Cole Waymeyer","Maggie Weeks")
## Alphabetical groups
size = 4
roster = m146s01 ## 8am
roster = m146s02 ## 9am
roster = m156s01 ## 12pm
n = ceiling(length(roster)/size)
v = rep(1:n, length.out = length(roster))
g = data.frame(roster, sort(v))
View(g)
sqrt(0.176*(1-0.176)/4981)
m146s01 = c("Connor Anderson", "Frankie Biffath","Lauren Briggs","David Brophy","Kayleigh Bush","Tom Cobb","Cameron Cyran","Anthony Dafforn","Laura DeNeve","Amanda Duminuco","Avery Dzurko","Sarah Fitch","Charles Johnson","Cristabel Kleiner","Erin Linko","Max Mesa","Claire Pape","Nevaeh Perkins","Bolu Salami","Benjamin Seibert","Sara Street","Abby Stumpf","Molly Sturm","Ana Torres","Renee White","Karolina Zawadzka")
get_groups <- function(roster, size = 4){
n = ceiling(length(roster)/size)
v = rep(1:n, length.out = length(roster))
out = data.frame(Name = roster, Group = sample(v, replace = FALSE))
return(out)
}
## Get groups
g <- get_groups(m146s01, size = 4)  ## 8am
## View groups
View(g)
g <- get_groups(m146s02, size = 4)  ## 9am
m146s02 = c("Miranda Basta","Brea Bauer","Olivia Bigham","Jason Bliss","Morgan Bowen","Richelle Cameron", "Aaliyah Coleman","Laura Cox","Fatoumata Diallo","Annabelle Fisher","Dylan Fraley","Amanda Hagedorn","Megan Humphry","Zach Kane","Cristabel Kleiner","Maeve Kruser","Ciara Lambert","Ant Mastrogiovanni-Washington","Samantha McCann","Sophia McDermott","Baylor McKinney","Isabella Roscoe","Max Rothkopf","Devon Terry","Anthony Toweson","Lizzie Troup")
g <- get_groups(m146s02, size = 4)  ## 9am
## View groups
View(g)
442958/490000
1836/2000
sqrt(0.904*(1-0.904)/2000)
1826/2000
